{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl # no train information\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas\n",
    "from utils import *\n",
    "from models.detector import *\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.manifold import TSNE\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "\n",
    "def set_seed(seed=3407):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class BWGNN_DB(nn.Module):\n",
    "    def __init__(self, in_feats=400, h_feats=32, num_classes=2, num_layers=2, mlp_layers=2, dropout_rate=0, **kwargs):\n",
    "        super().__init__()\n",
    "        self.thetas = calculate_theta(d=num_layers)\n",
    "        self.conv = []\n",
    "        for i in range(len(self.thetas)):\n",
    "            self.conv.append(PolyConv(self.thetas[i]))\n",
    "        self.linear = nn.Linear(in_feats, h_feats)\n",
    "        self.linear2 = nn.Linear(h_feats, h_feats)\n",
    "        self.mlp = MLP(h_feats*len(self.conv), h_feats, num_classes, mlp_layers, dropout_rate)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate) if dropout_rate > 0 else None\n",
    "\n",
    "    def forward(self, graph):\n",
    "        in_feat = graph.ndata['feature']\n",
    "        h = self.linear(in_feat)\n",
    "        h = self.act(h)\n",
    "        h = self.linear2(h)\n",
    "        h = self.act(h)\n",
    "        h_final = torch.zeros([len(in_feat), 0], device=h.device)\n",
    "\n",
    "        for conv in self.conv:\n",
    "            h0 = conv(graph, h)\n",
    "            h_final = torch.cat([h_final, h0], -1)\n",
    "        if self.dropout:\n",
    "            h_final = self.dropout(h_final)\n",
    "        h = self.mlp(h_final, False)\n",
    "\n",
    "        return h, h_final\n",
    "    \n",
    "class BWGNNDetector(BaseDetector):\n",
    "    def __init__(self, train_config, model_config, data):\n",
    "        super().__init__(train_config, model_config, data)\n",
    "        model_config['in_feats'] = self.data.graph.ndata['feature'].shape[1]\n",
    "        self.model = BWGNN_DB(**model_config).to(train_config['device'])\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.model_config['lr'])\n",
    "        train_labels, val_labels, test_labels = self.labels[self.train_mask], \\\n",
    "                                                self.labels[self.val_mask], self.labels[self.test_mask]\n",
    "        for e in range(self.train_config['epochs']):\n",
    "            self.model.train()\n",
    "            logits, hiddens = self.model(self.source_graph)\n",
    "            loss = F.cross_entropy(logits[self.train_mask], train_labels,\n",
    "                                   weight=torch.tensor([1., self.weight], device=self.labels.device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if self.model_config['drop_rate'] > 0:\n",
    "                self.model.eval()\n",
    "                logits = self.model(self.source_graph) \n",
    "            probs = logits.softmax(1)[:,1]\n",
    "            val_score = self.eval(val_labels, probs[self.val_mask])\n",
    "            if val_score[self.train_config['metric']] > self.best_score:\n",
    "                self.patience_knt = 0\n",
    "                self.best_score = val_score[self.train_config['metric']]\n",
    "                test_score = self.eval(test_labels, probs[self.test_mask])\n",
    "\n",
    "            else:\n",
    "                self.patience_knt += 1\n",
    "                if self.patience_knt > self.train_config['patience']:\n",
    "                    break\n",
    "        return test_score, hiddens\n",
    "    \n",
    "class GHRNDetector(BaseDetector):\n",
    "    def __init__(self, train_config, model_config, data):\n",
    "        super().__init__(train_config, model_config, data)\n",
    "        model_config['in_feats'] = self.data.graph.ndata['feature'].shape[1]\n",
    "        self.model = BWGNN_DB(**model_config).to(train_config['device'])\n",
    "\n",
    "    def random_walk_update(self, delete_ratio, adj_type):\n",
    "        graph = self.source_graph\n",
    "        edge_weight = torch.ones(graph.num_edges()).to(self.train_config['device'])\n",
    "        if adj_type == 'sym':\n",
    "            norm = dgl.nn.pytorch.conv.EdgeWeightNorm(norm='both')\n",
    "        else:\n",
    "            norm = dgl.nn.pytorch.conv.EdgeWeightNorm(norm='left')\n",
    "        graph.edata['w'] = norm(graph, edge_weight)\n",
    "        # functions\n",
    "        aggregate_fn = fn.u_mul_e('h', 'w', 'm')\n",
    "        reduce_fn = fn.sum(msg='m', out='ay')\n",
    "\n",
    "        graph.ndata['h'] = graph.ndata['feature']\n",
    "        graph.update_all(aggregate_fn, reduce_fn)\n",
    "        graph.ndata['ly'] = graph.ndata['feature'] - graph.ndata['ay']\n",
    "        # graph.ndata['lyyl'] = torch.matmul(graph.ndata['ly'], graph.ndata['ly'].T)\n",
    "        graph.apply_edges(self.inner_product_black)\n",
    "        # graph.apply_edges(inner_product_white)\n",
    "        black = graph.edata['inner_black']\n",
    "        # white = graph.edata['inner_white']\n",
    "        # delete\n",
    "        threshold = int(delete_ratio * graph.num_edges())\n",
    "        edge_to_move = set(black.sort()[1][:threshold].tolist())\n",
    "        # edge_to_protect = set(white.sort()[1][-threshold:].tolist())\n",
    "        edge_to_protect = set()\n",
    "        graph_new = dgl.remove_edges(graph, list(edge_to_move.difference(edge_to_protect)))\n",
    "        return graph_new\n",
    "\n",
    "    def inner_product_black(self, edges):\n",
    "        # if edges.src['ly'].shape[0] > 10000000\n",
    "        edges_num = edges.src['ly'].shape[0]\n",
    "        print(edges.src['ly'].shape, edges.dst['ly'].shape)\n",
    "        inner_black = torch.zeros([edges_num], device=edges.src['ly'].device)\n",
    "        step = 30000000\n",
    "        idx = 0\n",
    "        while idx < edges_num:\n",
    "            st = idx\n",
    "            idx += step\n",
    "            ed = idx if idx < edges_num else edges_num\n",
    "            inner_black[st:ed] = (edges.src['ly'][st:ed] * edges.dst['ly'][st:ed]).sum(1).detach().clone()\n",
    "            # f1 = features[edges.indices()[0,st:ed]]\n",
    "            # f2 = features[edges.indices()[1,st:ed]]\n",
    "        # inner_black = (edges.src['ly'] * edges.dst['ly']).sum(axis=1)\n",
    "        return {'inner_black': inner_black}\n",
    "\n",
    "    def train(self): # what is this ?\n",
    "        del_ratio = 0.015 if 'del_ratio' not in self.model_config else self.model_config['del_ratio']\n",
    "        adj_type = 'sym' if 'adj_type' not in self.model_config else self.model_config['adj_type']\n",
    "        if del_ratio != 0.:\n",
    "            graph = self.random_walk_update(del_ratio, adj_type)# If del_ratio is non-zero, the code applies random walk updates to the graph and ensures the graph has self-loops added.\n",
    "            graph = dgl.add_self_loop(dgl.remove_self_loop(graph))\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.model_config['lr'])\n",
    "        train_labels, val_labels, test_labels = self.labels[self.train_mask], \\\n",
    "                                                self.labels[self.val_mask], self.labels[self.test_mask]\n",
    "        for e in range(self.train_config['epochs']):\n",
    "            self.model.train()\n",
    "            logits, hiddens = self.model(graph)\n",
    "            loss = F.cross_entropy(logits[self.train_mask], train_labels,\n",
    "                                   weight=torch.tensor([1., self.weight], device=self.labels.device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            probs = logits.softmax(1)[:, 1]\n",
    "            val_score = self.eval(val_labels, probs[self.val_mask])\n",
    "            if val_score[self.train_config['metric']] > self.best_score:\n",
    "                self.patience_knt = 0\n",
    "                self.best_score = val_score[self.train_config['metric']]\n",
    "                test_score = self.eval(test_labels, probs[self.test_mask])\n",
    "            else:\n",
    "                self.patience_knt += 1\n",
    "                if self.patience_knt > self.train_config['patience']:\n",
    "                    break\n",
    "        return test_score, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = list(range(3500, 10000, 10))\n",
    "\n",
    "\n",
    "train_config = {\n",
    "    'device': 'cuda',\n",
    "    'epochs': 200,\n",
    "    'patience': 50,\n",
    "    'metric': 'AUPRC',\n",
    "    'seed': 3500,\n",
    "    'inductive': False,\n",
    "}\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, verbose=1, n_jobs=32)\n",
    "\n",
    "data = Dataset('tfinance')\n",
    "data.split(False,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin = GIN_noparam()\n",
    "feat = gin(data.graph)\n",
    "X_2d = tsne.fit_transform(feat)\n",
    "data.graph.ndata['feature'] = torch.tensor(X_2d)\n",
    "# xgb_detector1 = XGBoostDetector(train_config, {}, data1)\n",
    "set_seed()\n",
    "\n",
    "RF_detector1 = RFDetector(train_config, {}, data)\n",
    "mlp_detector1 = BaseGNNDetector(train_config, {'model': 'MLP', 'lr': 0.01, 'drop_rate':0}, data)\n",
    "mlp_detector1.train()\n",
    "RF_detector1.train()\n",
    "\n",
    "h = .1\n",
    "x_min, x_max = X_2d[:, 0].min() - .5, X_2d[:, 0].max() + .5\n",
    "y_min, y_max = X_2d[:, 1].min() - .5, X_2d[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z_MLP = (mlp_detector1.model.forward(torch.tensor(np.c_[xx.ravel(), yy.ravel()]).float().cuda(), is_graph=False).softmax(1).cpu().detach().numpy()[:,1]).reshape(xx.shape)\n",
    "Z_RF =RF_detector1.model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_RF =RF_detector1.model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1].reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = Dataset('tolokers')\n",
    "data2.split(False,1)\n",
    "\n",
    "# detector2 = BWGNNDetector(train_config,{ 'lr': 0.01, 'drop_rate':0}, data2)\n",
    "detector2 = GHRNDetector(train_config,{ 'lr': 0.01, 'drop_rate':0}, data2)\n",
    "score2, hiddens2 = detector2.train()\n",
    "\n",
    "feat2 = hiddens2.cpu().detach().numpy()\n",
    "X_2d2 = tsne.fit_transform(feat2)\n",
    "data2.graph.ndata['feature'] = torch.tensor(X_2d2)\n",
    "xgb_detector2 = XGBoostDetector(train_config, {}, data2)\n",
    "mlp_detector2 = BaseGNNDetector(train_config, {'model': 'MLP', 'lr': 0.01, 'drop_rate':0}, data2)\n",
    "mlp_detector2.train()\n",
    "xgb_detector2.train()\n",
    "\n",
    "x_min2, x_max2 = X_2d2[:, 0].min() - .5, X_2d2[:, 0].max() + .5\n",
    "y_min2, y_max2 = X_2d2[:, 1].min() - .5, X_2d2[:, 1].max() + .5\n",
    "xx2, yy2 = np.meshgrid(np.arange(x_min2, x_max2, h), np.arange(y_min2, y_max2, h))\n",
    "\n",
    "Z_BWGNN_MLP = (mlp_detector2.model.forward(torch.tensor(np.c_[xx2.ravel(), yy2.ravel()]).float().cuda(), is_graph=False).softmax(1).cpu().detach().numpy()[:,1]).reshape(xx2.shape)\n",
    "Z_BWGNN_XGB = xgb_detector2.model.predict_proba(np.c_[xx2.ravel(), yy2.ravel()])[:,1].reshape(xx2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "sz = 38\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "fig = plt.figure(figsize=(24, 6.6))\n",
    "gs = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 1])\n",
    "\n",
    "# ax1.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "        # Plot also the training points\n",
    "# ax1.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "s = 50\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax1.contourf(xx, yy, Z_MLP, cmap=plt.cm.RdBu, alpha=.7)\n",
    "ax1.scatter(X_2d[:, 0], X_2d[:, 1], c=data.graph.ndata['label'], marker='.',s=s, cmap=plt.cm.RdBu)\n",
    "ax1.set_title('GIN (T-Finance)', fontsize=sz)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=sz-10)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax2.contourf(xx, yy, Z_RF, cmap=plt.cm.RdBu, alpha=.7)\n",
    "ax2.scatter(X_2d[:, 0], X_2d[:, 1], c=data.graph.ndata['label'], marker='.',s=s, cmap=plt.cm.RdBu)\n",
    "ax2.set_title('RF-Graph (T-Finance)', fontsize=sz)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=sz-10)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "\n",
    "normal = data2.graph.ndata['label']==0\n",
    "anomaly = data2.graph.ndata['label']==1\n",
    "ax3 = plt.subplot(gs[2])\n",
    "ax3.contourf(xx2, yy2, Z_BWGNN_MLP, cmap=plt.cm.RdBu, alpha=.7)\n",
    "ax3.scatter(X_2d2[:, 0], X_2d2[:, 1], c=data2.graph.ndata['label'], marker='.',s=s, cmap=plt.cm.RdBu)\n",
    "\n",
    "\n",
    "ax3.set_title('GHRN (Tolokers)', fontsize=sz)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=sz-10)\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "ax4 = plt.subplot(gs[3])\n",
    "ax4.contourf(xx2, yy2, Z_BWGNN_XGB, cmap=plt.cm.RdBu, alpha=.7)\n",
    "ax4.scatter(X_2d2[:, 0], X_2d2[:, 1], c=data2.graph.ndata['label'], marker='.',s=s, cmap=plt.cm.RdBu)\n",
    "ax4.set_title('XGB-Graph (Tolokers)', fontsize=sz)\n",
    "ax4.tick_params(axis='both', which='major', labelsize=sz-10)\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "\n",
    "gs.update(wspace=0.1)\n",
    "gs.update(hspace=0.4)\n",
    "\n",
    "plt.subplots_adjust(left=0.01, right=0.99, top=0.92, bottom=0.02)\n",
    "# plt.savefig('DecisionBoundary_6.png', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
